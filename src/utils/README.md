# Modelos de Clasificaci√≥n de Noticias Falsas

Este proyecto implementa dos enfoques diferentes para la clasificaci√≥n de noticias falsas usando deep learning: un modelo basado en **BERT** (Transformer) y un modelo **RNN** personalizado.

## Tabla de Contenidos
- [Modelo BERT](#modelo-bert)
- [Modelo RNN](#modelo-rnn)

## Modelo BERT

### Arquitectura Base
- **Modelo**: DistilBERT-base-uncased (por defecto)
- **Tipo**: Transformer pre-entrenado con fine-tuning
- **Par√°metros**: ~66M par√°metros (DistilBERT)

### Configuraci√≥n del Modelo

#### Tokenizaci√≥n
- **Tokenizer**: AutoTokenizer de Transformers
- **Longitud m√°xima**: 512 tokens
- **Padding**: 'max_length'
- **Truncation**: Habilitado

#### Arquitectura de Clasificaci√≥n
```
DistilBERT Base ‚Üí Classification Head
‚îú‚îÄ‚îÄ Hidden Size: 768
‚îú‚îÄ‚îÄ Attention Heads: 12
‚îú‚îÄ‚îÄ Hidden Layers: 6
‚îî‚îÄ‚îÄ Classification Layer: Linear(768 ‚Üí 2)
```

#### Configuraci√≥n de Entrenamiento
- **Optimizador**: AdamW
  - Learning Rate: 2e-5
  - Weight Decay: 0.01 (por defecto)
- **Loss Function**: CrossEntropyLoss
- **Scheduler**: Linear con warmup
  - Warmup Steps: 0
- **Gradient Clipping**: 1.0
- **Batch Size**: 16 (por defecto)
- **√âpocas**: 3 (por defecto)

#### Funciones de Activaci√≥n
- **BERT Layers**: GELU (en capas internas)
- **Classification Head**: Linear (sin activaci√≥n, logits directos)

### Caracter√≠sticas Especiales
- **Attention Mechanism**: Multi-head self-attention
- **Transfer Learning**: Fine-tuning de modelo pre-entrenado
- **Regularizaci√≥n**: Dropout impl√≠cito en BERT layers

---

## Modelo RNN

### Arquitectura Base
- **Tipo**: LSTM/GRU bidireccional personalizado
- **Enfoque**: Entrenamiento desde cero

### Configuraci√≥n del Modelo

#### Preprocesamiento de Texto
- **Tokenizaci√≥n**: NLTK word_tokenize
- **Filtros aplicados**:
  - URLs y links removidos
  - Caracteres especiales filtrados
  - N√∫meros eliminados
  - Stopwords removidas
  - Conversi√≥n a min√∫sculas
- **Vocabulario**:
  - Tama√±o m√°ximo: 20,000 tokens
  - Frecuencia m√≠nima: 3
  - Tokens especiales: `<PAD>`, `<UNK>`

#### Arquitectura de Red
```
Embedding Layer (vocab_size ‚Üí 128)
    ‚Üì
LSTM/GRU Bidireccional
‚îú‚îÄ‚îÄ Hidden Dim: 256
‚îú‚îÄ‚îÄ Num Layers: 2
‚îú‚îÄ‚îÄ Bidirectional: True
‚îî‚îÄ‚îÄ Dropout: 0.4 (entre capas)
    ‚Üì
Fully Connected Layers
‚îú‚îÄ‚îÄ BatchNorm1d(512) ‚Üí FC(512 ‚Üí 256) ‚Üí ReLU ‚Üí Dropout(0.4)
‚îú‚îÄ‚îÄ BatchNorm1d(256) ‚Üí FC(256 ‚Üí 128) ‚Üí ReLU ‚Üí Dropout(0.4)
‚îú‚îÄ‚îÄ BatchNorm1d(128) ‚Üí FC(128 ‚Üí 64) ‚Üí ReLU
‚îî‚îÄ‚îÄ FC(64 ‚Üí 2) [Output]
```

#### Configuraci√≥n de Entrenamiento
- **Optimizador**: Adam
  - Learning Rate: 0.001
  - Weight Decay: 1e-4
- **Loss Function**: CrossEntropyLoss
- **Scheduler**: ReduceLROnPlateau
  - Patience: 3
  - Factor: 0.5
- **Gradient Clipping**: 1.0
- **Batch Size**: 32 (por defecto)
- **√âpocas**: 15 (por defecto)

#### Funciones de Activaci√≥n
- **RNN Gates**: Sigmoid y Tanh (LSTM) / Sigmoid (GRU)
- **Dense Layers**: ReLU
- **Output Layer**: Linear (logits)

#### Regularizaci√≥n
- **Dropout**: 0.4 (configurable)
- **Batch Normalization**: En todas las capas densas
- **Early Stopping**: Patience de 7 √©pocas
- **Gradient Clipping**: Norma m√°xima de 1.0

### Configuraciones Personalizables
- **RNN Type**: LSTM o GRU
- **Bidireccional**: True/False
- **Embedding Dimension**: 128 (por defecto)
- **Hidden Dimension**: 256 (por defecto)
- **N√∫mero de Capas RNN**: 2 (por defecto)
- **Longitud de Secuencia**: 200 tokens (por defecto)

---

## ‚öñÔ∏è Comparaci√≥n de Modelos

| Caracter√≠stica | BERT | RNN |
|----------------|------|-----|
| **Arquitectura** | Transformer pre-entrenado | RNN/LSTM bidireccional |
| **Par√°metros** | ~66M | ~1-5M (dependiendo config) |
| **Entrenamiento** | Fine-tuning | Desde cero |
| **Memoria GPU** | Alta | Moderada |
| **Tiempo de entrenamiento** | R√°pido (pocas √©pocas) | Moderado (m√°s √©pocas) |
| **Longitud de secuencia** | 512 tokens | 200 tokens |
| **Preprocesamiento** | M√≠nimo (tokenizer) | Extensivo (limpieza manual) |
| **Generalizaci√≥n** | Excelente | Buena |
| **Interpretabilidad** | Limitada | Moderada |


## üìä M√©tricas de Evaluaci√≥n

Ambos modelos proporcionan:
- **Accuracy**: Precisi√≥n general
- **Classification Report**: Precision, Recall, F1-score por clase
- **Confusion Matrix**: Matriz de confusi√≥n
- **Loss Curves**: P√©rdida de entrenamiento y validaci√≥n
- **Probabilidades**: Confianza en las predicciones